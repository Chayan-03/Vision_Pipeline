# Gloved vs Ungloved Hand Detection

This folder contains:

- `detection_script.py` â€” Inference script that reads a folder of images and outputs annotated images + per-image JSON logs.
- `output_folder/` â€” Sample annotated images (add 3â€“5 images after you run the script).
- `detections_logs/` â€” Per-image JSON logs in the required schema generted by the script.
- `models/` - folder containing YOLOv8 weights.
- `input_folder/` - folder conatining images to be processed.

---

## ğŸ“‚ Project Structure
```
CVPipeline/
â”‚â”€â”€ detection_script.py     # Main inference script
â”‚â”€â”€ requirements.txt        # Python dependencies
â”‚â”€â”€ README.md               # Project documentation
â”‚â”€â”€ models/                 # Place your trained YOLO weights (best.pt)
â”‚â”€â”€ input_folder/           # Folder containing input images
â”‚â”€â”€ output_folder/          # Annotated images will be saved here
â”‚â”€â”€ detections_logs/        # JSON logs for detections will be saved here
```

---

## âš™ï¸ Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/Vision_Pipeline.git
   cd Vision_Pipeline
   ```

2. Create and activate a virtual environment (recommended):
   ```bash
   python -m venv .venv
   source .venv/bin/activate   # Linux/Mac
   .venv\Scripts\activate      # Windows
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

---

## â–¶ï¸ Running Inference
Run the script with:

```bash
python detection_script.py \
  --weights models/best.pt \
  --input input_folder \
  --output output_folder \
  --logs detections_logs \
  --conf 0.25
```

### Arguments:
- `--weights` â†’ Path to YOLOv8 weights (`best.pt`)  
- `--input` â†’ Folder containing input images  
- `--output` â†’ Folder where annotated images will be saved  
- `--logs` â†’ Folder where JSON detection logs will be stored  
- `--conf` â†’ Confidence threshold (default: 0.25, recommend: 0.25â€“0.5)  

---

## ğŸ“ Output
1. **Annotated images** â†’ saved in `output_folder`  
2. **JSON logs** â†’ one per image, stored in `detections_logs/`  

### Example JSON log:
```json
{
  "filename": "image1.jpg",
  "detections": [
    {
      "label": "Hand in glove detection",
      "confidence": 0.87,
      "bbox": [100.5, 200.3, 250.8, 400.6]
    }
  ]
}
```
If  bare hand is detected:
```json
{
  "filename": "image2.jpg",
  "detections": [
    {
      "label": "Hand",
      "confidence": 0.0,
      "bbox": []
    }
  ]
}
```
## ğŸ“Š Example Terminal Output
```
[image1.jpg] glove detected with confidence 0.87
[image2.jpg] hand detected with confidence 0.42
[image3.jpg] No detection â†’ assuming no detection in the image
```
